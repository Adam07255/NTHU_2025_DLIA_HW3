{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個HW3＿4是使用原本的resnet 18 加上針對good以外的種類進行額外的資料強"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from tqdm.auto import tqdm\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "base_path = \"/Users/adam0725/1332/1233/Pratice/train\"\n",
    "\n",
    "image_label_pairs = []\n",
    "\n",
    "for root, dirs, files in os.walk(base_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            full_path = os.path.join(root, file)\n",
    "            class_folder = os.path.basename(os.path.dirname(full_path))\n",
    "            label = 0 if \"good\" in class_folder.lower() else 1\n",
    "            image_label_pairs.append((full_path, label))\n",
    "\n",
    "# 顯示前幾筆確認\n",
    "print(\"共載入圖片數量：\", len(image_label_pairs))\n",
    "print(\"前 3 筆：\", image_label_pairs[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 讀入所有影像與標籤\n",
    "all_images = []\n",
    "all_labels = []\n",
    "\n",
    "for path, label in image_label_pairs:\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.resize(img, (224, 224))  # \n",
    "    img = img[..., ::-1]  # BGR → RGB\n",
    "    # img = img.astype(np.float32) / 255.0  \n",
    "    all_images.append(img)\n",
    "    all_labels.append(label)\n",
    "\n",
    "# 轉為 tensor\n",
    "x = torch.tensor(np.array(all_images)).permute(0, 3, 1, 2)  # N, C, H, W\n",
    "y = torch.tensor(all_labels).float().unsqueeze(1)  # N, 1\n",
    "\n",
    "# 切分訓練/驗證集（7:3）\n",
    "x_train, x_val, y_train, y_val = train_test_split(x, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "# 包裝為 DataLoader\n",
    "train_dataset = TensorDataset(x_train, y_train)\n",
    "val_dataset = TensorDataset(x_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class_names = sorted(set([os.path.basename(os.path.dirname(p)) for p, _ in image_label_pairs]))\n",
    "print(f'Classes: {class_names}')\n",
    "\n",
    "img_per_class = 5\n",
    "fig, axs = plt.subplots(len(class_names), img_per_class, figsize=(6, 4 * len(class_names)))\n",
    "\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    \n",
    "    class_indices = [idx for idx, (path, _) in enumerate(image_label_pairs) if class_name in path]\n",
    "\n",
    "    for j in range(img_per_class):\n",
    "        img = all_images[class_indices[j]]\n",
    "        ax = axs[i, j] if len(class_names) > 1 else axs[j]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(f'{class_name} [{j}]')\n",
    "        ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset, random_split\n",
    "import numpy as np\n",
    "\n",
    "num_classes = 5\n",
    "images_per_class = 10\n",
    "train_images_per_class = int(images_per_class * 0.8)\n",
    "val_images_per_class = int(images_per_class * 0.2)\n",
    "\n",
    "x_train = []\n",
    "x_val = []\n",
    "\n",
    "for i in range(num_classes):\n",
    "    start_index = i * images_per_class\n",
    "    x_train.extend(all_images[start_index:start_index + train_images_per_class])\n",
    "    x_val.extend(all_images[start_index + train_images_per_class:start_index + images_per_class])\n",
    "\n",
    "# The shape changes from (batch_size, height, width, channels) to (batch_size, channels, height, width)\n",
    "x_train = np.transpose(np.array(x_train), (0, 3, 1, 2))\n",
    "x_val = np.transpose(np.array(x_val), (0, 3, 1, 2))\n",
    "\n",
    "y_train = np.concatenate([np.full(train_images_per_class, i) for i in range(num_classes)])\n",
    "y_val = np.concatenate([np.full(val_images_per_class, i) for i in range(num_classes)])\n",
    "\n",
    "print(f'Shape of x_train: {x_train.shape}')\n",
    "print(f'Shape of x_val: {x_val.shape}')\n",
    "print(f'Shape of y_train: {y_train.shape}')\n",
    "print(f'Shape of y_val: {y_val.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# 對 good 類別使用保守轉換\n",
    "good_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# 對瑕疵類別使用強化增強\n",
    "defect_transforms = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(30),\n",
    "    transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3),\n",
    "    transforms.RandomPerspective(distortion_scale=0.3, p=0.5),\n",
    "    transforms.RandomAffine(degrees=20, shear=10),\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, x, y, class_names):\n",
    "        self.x = x\n",
    "        self.y = torch.from_numpy(y).long()\n",
    "        self.class_names = class_names  # e.g., ['bent_2', 'color_2', 'flip_2', 'good', 'scratch_2']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img = self.x[idx]\n",
    "        img_array = np.transpose(img, (1, 2, 0))  # (H, W, 3)\n",
    "        img_array = np.clip(img_array * 255, 0, 255).astype('uint8')\n",
    "\n",
    "        if img_array.shape != (224, 224, 3):\n",
    "            print(f'[WARNING] Unexpected shape: {img_array.shape} (index {idx})')\n",
    "            img_array = np.zeros((224, 224, 3), dtype='uint8')\n",
    "\n",
    "        image = Image.fromarray(img_array)\n",
    "\n",
    "        label = int(self.y[idx])\n",
    "        class_name = self.class_names[label]\n",
    "\n",
    "        # 根據類別選擇增強方式\n",
    "        if class_name == 'good':\n",
    "            image = good_transforms(image)\n",
    "        else:\n",
    "            image = defect_transforms(image)\n",
    "\n",
    "        return image, label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "class_names = ['bent_2', 'color_2', 'flip_2', 'good', 'scratch_2']\n",
    "train_dataset = MyDataset(x_train, y_train, class_names=class_names)\n",
    "val_dataset = MyDataset(x_val, y_val, class_names=class_names)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, num_workers=0,pin_memory=False)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=batch_size, shuffle=False, num_workers=0,pin_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import models\n",
    "\n",
    "model = models.resnet18(weights='IMAGENET1K_V1')\n",
    "\n",
    "# ConvNet as fixed feature extractor (freeze parameters)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_ftrs = model.fc.in_features\n",
    "num_class = 5\n",
    "\n",
    "# change # of class from 1000 into 8 in the last layer\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_ftrs, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    nn.Linear(256, num_class)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, StepLR\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "epochs = 20\n",
    "\n",
    "\n",
    "model = model  \n",
    "\n",
    "best_val_loss = float('inf')\n",
    "best_val_acc = -1\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "lr_scheduler = CosineAnnealingLR(optimizer, T_max=len(train_loader)*epochs, eta_min=0)\n",
    "\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # Training\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    train_correct = 0\n",
    "    total_train_samples = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "     \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        labels = labels.long()\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        train_predicted = outputs.argmax(-1)\n",
    "        train_correct += (train_predicted == labels).sum().item()\n",
    "        total_train_samples += labels.size(0)\n",
    "\n",
    "    avg_train_loss = total_loss / len(train_loader)\n",
    "    train_accuracy = 100. * train_correct / total_train_samples\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "         \n",
    "            #images = images / 255.\n",
    "        \n",
    "            outputs = model(images)\n",
    "            labels = labels.long()\n",
    "\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item()\n",
    "\n",
    "            predicted = outputs.argmax(-1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    val_accuracy = 100. * correct / total\n",
    "\n",
    "    # Learning rate update\n",
    "    lr_scheduler.step()\n",
    "\n",
    "    # Checkpoint\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "\n",
    "    if val_accuracy > best_val_acc:\n",
    "        best_val_acc = val_accuracy\n",
    "        torch.save(model.state_dict(), 'model_classification.pth')\n",
    "\n",
    "    print(f'Epoch {epoch+1}/{epochs}, Train loss: {avg_train_loss:.4f}, Train acc: {train_accuracy:.4f}%, Val loss: {avg_val_loss:.4f}, Val acc: {val_accuracy:.4f}%, Best Val loss: {best_val_loss:.4f} Best Val acc: {best_val_acc:.2f}%')\n",
    "\n",
    "    # Store performance\n",
    "    train_losses.append(avg_train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "    val_losses.append(avg_val_loss)\n",
    "    val_accuracies.append(val_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Plotting training and validation accuracy\n",
    "ax[0].plot(train_accuracies)\n",
    "ax[0].plot(val_accuracies)\n",
    "ax[0].set_title('Model Accuracy')\n",
    "ax[0].set_xlabel('Epochs')\n",
    "ax[0].set_ylabel('Accuracy')\n",
    "ax[0].legend(['Train', 'Val'])\n",
    "\n",
    "# Plotting training and validation loss\n",
    "ax[1].plot(train_losses)\n",
    "ax[1].plot(val_losses)\n",
    "ax[1].set_title('Model Loss')\n",
    "ax[1].set_xlabel('Epochs')\n",
    "ax[1].set_ylabel('Loss')\n",
    "ax[1].legend(['Train', 'Val'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained weights\n",
    "model.load_state_dict(torch.load('model_classification.pth'))\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in val_loader:\n",
    "\n",
    "        \n",
    "        # images = (images) / 255.\n",
    "\n",
    "      \n",
    "        labels = labels.long()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        predicted = outputs.argmax(-1)\n",
    "        print(predicted)\n",
    "        print(labels)\n",
    "        test_correct += (predicted == labels).sum().item()\n",
    "        test_total += labels.size(0)\n",
    "\n",
    "print(f'Test accuracy is {100. * test_correct / test_total}%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
